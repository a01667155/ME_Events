{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from Load_RGB import CASME2Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from torchvision.models.video import r3d_18\n",
    "\n",
    "# Modelo ResNet 3D (acepta datos de forma [batch_size, C, T, H, W])\n",
    "model = r3d_18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 3)  # Ajustar la última capa\n",
    "\n",
    "# Mover modelo a GPU si está disponible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "database = CASME2Dataset()\n",
    "\n",
    "total_size = database.__len__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8  # 80% para entrenamiento, 20% para prueba\n",
    "train_size = int(train_ratio * total_size)\n",
    "test_size = total_size - train_size\n",
    "\n",
    "# Dividir el dataset\n",
    "train_dataset, test_dataset = random_split(database, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Definir función de pérdida\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Definir optimizador\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "model.train()  # Poner el modelo en modo de entrenamiento\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "\n",
    "    for videos, labels in train_loader:\n",
    "        videos, labels = videos.to(device), labels.to(device)  # Mover datos a GPU si está disponible\n",
    "\n",
    "        # Reiniciar gradientes\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Hacer forward y calcular pérdida\n",
    "        outputs = model(videos)  # Pasar los videos por el modelo\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Hacer backward y optimizar\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    if epoch%5 == 0:\n",
    "        checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss}\n",
    "        torch.save(checkpoint, 'D:\\PythonCourse\\ME_Recognition\\Data\\models\\checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Cambiar a modo de evaluación\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # Desactivar cálculo de gradientes\n",
    "    for videos, labels in test_loader:\n",
    "        videos, labels = videos.to(device), labels.to(device)\n",
    "        outputs = model(videos)\n",
    "        _, predicted = torch.max(outputs, 1)  # Obtener la clase con mayor probabilidad\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar los índices utilizados en el split\n",
    "train_indices = train_dataset.indices\n",
    "test_indices = test_dataset.indices\n",
    "\n",
    "torch.save({'train': train_indices, 'test': test_indices}, 'D:\\PythonCourse\\ME_Recognition\\Data\\models\\split_indices.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss\n",
    "    }\n",
    "torch.save(checkpoint, 'D:\\PythonCourse\\ME_Recognition\\Data\\models\\checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'D:\\PythonCourse\\ME_Recognition\\Data\\models\\\\r3d_18_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cargar el archivo de video\n",
    "# cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# # Verificar si se pudo abrir correctamente\n",
    "# if not cap.isOpened():\n",
    "#     print(\"No se pudo abrir el archivo de video.\")\n",
    "#     exit()\n",
    "\n",
    "# # Leer y mostrar cada cuadro del video\n",
    "# while True:\n",
    "#     ret, frame = cap.read()\n",
    "    \n",
    "#     # Si no hay más cuadros, salir del bucle\n",
    "#     if not ret:\n",
    "#         print(\"Fin del video o no se pudieron leer más cuadros.\")\n",
    "#         break\n",
    "\n",
    "#     # Mostrar el cuadro en una ventana\n",
    "#     cv2.imshow(\"Video\", frame)\n",
    "    \n",
    "#     # Salir si se presiona la tecla 'q'\n",
    "#     if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Liberar el recurso del video y cerrar las ventanas\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PythonCourse\\ME_Recognition\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\PythonCourse\\ME_Recognition\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=R3D_18_Weights.KINETICS400_V1`. You can also use `weights=R3D_18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from Load_RGB import CASME2Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.optim as optim\n",
    "from torchvision.models.video import r3d_18\n",
    "\n",
    "# Modelo ResNet 3D (acepta datos de forma [batch_size, C, T, H, W])\n",
    "model = r3d_18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 3)  # Ajustar la última capa\n",
    "\n",
    "# Mover modelo a GPU si está disponible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Dataset\n",
    "database = CASME2Dataset()  # ¿Necesita argumentos adicionales?\n",
    "\n",
    "# Definir función de pérdida\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Cargar el checkpoint con el dispositivo adecuado\n",
    "checkpoint = torch.load('D:\\PythonCourse\\ME_Recognition\\Data\\models\\checkpoint.pth', map_location=device)\n",
    "\n",
    "# Restaurar el estado del modelo y del optimizador\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Definir y cargar el optimizador\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Asegúrate de que lr sea el mismo\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# Recuperar la epoch, batch y pérdida\n",
    "start_epoch = checkpoint['epoch']\n",
    "start_batch = checkpoint.get('batch', 0)  # Opcional\n",
    "loss_value = checkpoint.get('loss', None)  # Opcional\n",
    "\n",
    "# Cargar los índices de entrenamiento y prueba\n",
    "split_indices = torch.load('D:\\PythonCourse\\ME_Recognition\\Data\\models\\split_indices.pth')\n",
    "train_indices = split_indices['train']\n",
    "test_indices = split_indices['test']\n",
    "\n",
    "# Crear subsets\n",
    "train_dataset = Subset(database, train_indices)\n",
    "test_dataset = Subset(database, test_indices)\n",
    "\n",
    "# Configuración del DataLoader\n",
    "batch_size = 2  # Considera aumentar este valor si es posible\n",
    "torch.manual_seed(42)  # Reproducibilidad\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.0246\n",
      "Epoch [2/5], Loss: 1.0021\n",
      "Epoch [3/5], Loss: 1.0088\n",
      "Epoch [4/5], Loss: 1.0068\n",
      "Epoch [5/5], Loss: 0.9771\n"
     ]
    }
   ],
   "source": [
    "start_epoch = epoch\n",
    "num_epochs = 10\n",
    "model.train()  # Poner el modelo en modo de entrenamiento\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "\n",
    "    for videos, labels in train_loader:\n",
    "        videos, labels = videos.to(device), labels.to(device)  # Mover datos a GPU si está disponible\n",
    "\n",
    "        # Reiniciar gradientes\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Hacer forward y calcular pérdida\n",
    "        outputs = model(videos)  # Pasar los videos por el modelo\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Hacer backward y optimizar\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    if epoch%2 == 0:\n",
    "        checkpoint = {\n",
    "        'epoch': epoch+start_epoch+1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss}\n",
    "        torch.save(checkpoint, 'D:\\PythonCourse\\ME_Recognition\\Data\\models\\checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 54.90%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Cambiar a modo de evaluación\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # Desactivar cálculo de gradientes\n",
    "    for videos, labels in test_loader:\n",
    "        videos, labels = videos.to(device), labels.to(device)\n",
    "        outputs = model(videos)\n",
    "        _, predicted = torch.max(outputs, 1)  # Obtener la clase con mayor probabilidad\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
